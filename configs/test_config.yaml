# Model Architecture
model:
  use_concat: True
  max_seq_length: 16
  embed_dim: 33
  num_heads: 3
  num_layers: 1
  dropout: 0.1
  resample_size: 1000

# Training Parameters
training:
  batch_size: 32
  test_batch_size: 1
  num_epochs: 1
  learning_rate: 1.0e-4
  min_learning_rate: 1.0e-5
  validation_frequency: 50
  logging_frequency: 10
  save_frequency: 1000

# Scheduler
scheduler:
  warmup_steps: 100
  T0: 5
  T_mult: 2

# Data
data:
  use_parquet: False
  data_dir: "tokenized_baseline"
  binary_dir: "preprocessed_binaries"
  test_size: 20
  val_size: 0.001
  preprocessed: False

# Logging
wandb:
  project: "smiles-generation"
  base_run_name: "smiles_gen"
  log_examples: true 